{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "443be525",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ymoslem/Sentence-Similarity/blob/main/Semantic_Search_Faiss_Multilingual.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pwP51drINgo0",
   "metadata": {
    "id": "pwP51drINgo0"
   },
   "source": [
    "# Multilingual Semantic Search with Faiss\n",
    "\n",
    "This notebook demonstrates how to use Faiss and Sentence-Transformers to perform multilingual semantic search. We have a query in English (\"education and schools in Germany\") and we retrieve top results from documents in the Ukrainian language.\n",
    "\n",
    "* Faiss: https://github.com/facebookresearch/faiss\n",
    "* Faiss tutorial: https://www.pinecone.io/learn/series/faiss/faiss-tutorial/\n",
    "* Sentence-Transformers: https://github.com/UKPLab/sentence-transformers\n",
    "* Sentence-Transformers documentation: https://sbert.net/\n",
    "\n",
    "* Notebooks for some other similarity techniques [here](https://github.com/ymoslem/Sentence-Similarity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PaWDsWhfMbT1",
   "metadata": {
    "id": "PaWDsWhfMbT1"
   },
   "outputs": [],
   "source": [
    "!pip3 install faiss-gpu sentence_transformers -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1O6NDId7KRwm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1O6NDId7KRwm",
    "outputId": "28a02ef6-c060-47ad-beee-e174b0d0ac87"
   },
   "outputs": [],
   "source": [
    "# Download files\n",
    "!git clone https://github.com/ymoslem/Notion-Scraper.git -q\n",
    "\n",
    "%cd Notion-Scraper/output/\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49035623",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "49035623",
    "outputId": "261e0cb2-02e8-45d3-ce7e-ee5b9fe92ba4"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "work_dir = \".\"\n",
    "json_files = [file_name for file_name in os.listdir(work_dir) if file_name.endswith(\".json\")]\n",
    "\n",
    "corpus = []\n",
    "\n",
    "for json_file in json_files:\n",
    "  with open(os.path.join(work_dir,json_file)) as json_input:\n",
    "    json_content = json.load(json_input)\n",
    "    for item in json_content:\n",
    "      url = item[\"url\"]\n",
    "      text_paragraphs = item[\"text\"].split(\"\\n\")\n",
    "      text_paragraphs = [(para, json_file[:-5], item[\"topic\"], item[\"url\"]) for para in text_paragraphs if len(para.split())>10 \\\n",
    "                     and (para, json_file[:-5], item[\"topic\"], item[\"url\"]) not in corpus]\n",
    "      corpus += text_paragraphs\n",
    "\n",
    "corpus[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896a83a6",
   "metadata": {
    "id": "896a83a6"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "corpus_sentences = [item[0] for item in corpus]\n",
    "\n",
    "embedder = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\",\n",
    "                               device=\"cuda\")\n",
    "\n",
    "# Change the max length to 512\n",
    "embedder.max_seq_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sZ_PCGUzv2vs",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "2e4a33a0f7f74eaf9430a31ad6a12cda",
      "495d9ee4f07d4ba99a02e18d3508c73f",
      "e711bf223a594e3da579717bc2dc7192",
      "02fd8b9f9ee54c91b62db712026cc954",
      "f266a00bd38a4698a084377341688a9d",
      "cc14214bb177429e94aea83147a41276",
      "e1af658017b94ecdad420ac828614379",
      "3268379f635a4ee08a812115a71ea807",
      "fbc8b9ba4ac24cfba548d789966083c5",
      "5e3a92f8d04d45698410b413e224eedf",
      "d3dd1c9402b0414483d027cbabe51be9"
     ]
    },
    "id": "sZ_PCGUzv2vs",
    "outputId": "7229c217-e076-4d25-8459-bc4cdfd545c3"
   },
   "outputs": [],
   "source": [
    "# Encode the sentences into embeddings\n",
    "corpus_embeddings = embedder.encode(corpus_sentences,\n",
    "                                    convert_to_numpy=True,\n",
    "                                    show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e285b2f",
   "metadata": {
    "id": "5e285b2f"
   },
   "outputs": [],
   "source": [
    "# Save corpus_embeddings to a file to be able to load later\n",
    "import pickle\n",
    "\n",
    "with open(\"corpus_embeddings_uk.pkl\", \"wb\") as embeddings:\n",
    "  pickle.dump({'corpus': corpus, 'embeddings': corpus_embeddings}, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b69fdb",
   "metadata": {
    "id": "46b69fdb"
   },
   "outputs": [],
   "source": [
    "# To load the embeddings later from the file instead of creating from scratch\n",
    "import pickle\n",
    "\n",
    "with open(\"corpus_embeddings_uk.pkl\", \"rb\") as embeddings:\n",
    "  data = pickle.load(embeddings)\n",
    "  corpus = data['corpus']\n",
    "  corpus_sentences = [item[0] for item in corpus]\n",
    "  corpus_embeddings = data['embeddings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f039fd50",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f039fd50",
    "outputId": "cce4d36c-7fdc-48bb-dddc-af156d656597"
   },
   "outputs": [],
   "source": [
    "corpus_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0459721",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e0459721",
    "outputId": "6281ee39-167d-4e19-9630-0c7e9d013fa1"
   },
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "embedding_size = 384  # as in the model\n",
    "n_clusters = 128\n",
    "top_k_hits = 20\n",
    "\n",
    "quantizer = faiss.IndexFlatL2(embedding_size)\n",
    "index = faiss.IndexIVFFlat(quantizer, embedding_size, n_clusters)\n",
    "\n",
    "# Number of clusters to explorer at search time.\n",
    "# We will search for nearest neighbors in 8 clusters\n",
    "index.nprobe = 8\n",
    "\n",
    "### Create the FAISS index\n",
    "print(\"Start creating FAISS index\")\n",
    "\n",
    "# Train the index to find a suitable clustering\n",
    "index.train(corpus_embeddings)\n",
    "\n",
    "# Add all embeddings to the index\n",
    "index.add(corpus_embeddings)\n",
    "\n",
    "print(\"Number of embeddings indexed:\", index.ntotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7484600b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7484600b",
    "outputId": "225f015b-c547-46da-e63b-1be18975ea13"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "queries = [\"education and schools in Germany\"]\n",
    "model_name = \"paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "query_embeddings = model.encode(queries)\n",
    "\n",
    "# Search in FAISS. It returns a matrix with distances and corpus ids.\n",
    "distances, corpus_ids = index.search(query_embeddings, k=top_k_hits)\n",
    "\n",
    "print(corpus_ids, \"\\n\")\n",
    "\n",
    "results = sorted([result for result in zip(distances.flatten(), corpus_ids.flatten())])\n",
    "print(results, \"\\n\")\n",
    "\n",
    "for distance, idx in results:\n",
    "  print(corpus_sentences[idx])\n",
    "  print(f\"Read more: {corpus[idx][1]} - {corpus[idx][2]}: {corpus[idx][3]}\")\n",
    "  print(f\"Distance: {round(distance.item(), 2)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UKOHBe70Sf_C",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UKOHBe70Sf_C",
    "outputId": "deec5e1d-9c9f-41ad-dc72-62e5da7e53e6"
   },
   "outputs": [],
   "source": [
    "results[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DdHkGHkAT1rw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DdHkGHkAT1rw",
    "outputId": "2451c3b4-83ba-4741-c095-bfc360de743a"
   },
   "outputs": [],
   "source": [
    "# Reranking input [(query, paragraph), (query, paragraph), (query, paragraph), ...]\n",
    "\n",
    "reranker_input = [(queries[0], corpus[result[1]][0]) for result in results]\n",
    "reranker_input[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ek6bBXPRDhW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ek6bBXPRDhW",
    "outputId": "6d5c2789-154d-4fad-984a-a01e87273ad5"
   },
   "outputs": [],
   "source": [
    "# [Optional] Reranking\n",
    "# After retrieving the top-k candidates, we can re-rank them with a cross-encoder model\n",
    "\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "model = CrossEncoder(\"amberoad/bert-multilingual-passage-reranking-msmarco\", max_length=512)\n",
    "\n",
    "reranker_scores = model.predict(reranker_input)\n",
    "\n",
    "# label 0: not relevant, and label 1: relevant\n",
    "reranker_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "k73AZlBTOn8s",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k73AZlBTOn8s",
    "outputId": "a8c8bfc0-d2dd-443f-d4e6-d48183e38954"
   },
   "outputs": [],
   "source": [
    "# [Optional] Convert logits to probabilities for readability or to apply a threshold\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Convert logits to probabilities using the sigmoid function\n",
    "reranker_scores = [1 / (1 + np.exp(-score)) for score in reranker_scores]\n",
    "reranker_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VMKkxCQfd7Nv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VMKkxCQfd7Nv",
    "outputId": "822b36e3-5826-4872-e867-65bb465ae86d"
   },
   "outputs": [],
   "source": [
    "# full hits from the corpus with links\n",
    "full_hits = [[result[0], corpus[result[1]]] for result in results]\n",
    "reranker_output = zip(reranker_scores, full_hits)\n",
    "\n",
    "# Compare the results before and after reranking\n",
    "# for score, hit in zip(reranker_scores, full_hits):\n",
    "#   print(score, hit)\n",
    "\n",
    "sorted_reranked_output = sorted([(score[1], hit[1]) for score, hit in reranker_output], reverse=True)\n",
    "\n",
    "for score, hit in sorted_reranked_output:\n",
    "  print(f\"{hit[0]} \\nRead more: {hit[1]} - {hit[2]}: {hit[3]} \\nScore: {round(score.item(), 2)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ec652d",
   "metadata": {
    "id": "62ec652d"
   },
   "source": [
    "# GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b915e5",
   "metadata": {
    "id": "e3b915e5"
   },
   "outputs": [],
   "source": [
    "# To load the embeddings later from the file instead of creating from scratch\n",
    "import pickle\n",
    "\n",
    "with open(\"corpus_embeddings_uk.pkl\", \"rb\") as embeddings:\n",
    "    data = pickle.load(embeddings)\n",
    "    corpus = data['corpus']\n",
    "    corpus_sentences = [item[0] for item in corpus]\n",
    "    corpus_embeddings = data['embeddings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3add4241",
   "metadata": {
    "id": "3add4241"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Which GPU to use (if you have multiple GPUs)\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"  # or \"0,1\" for multiple gpus\n",
    "\n",
    "# For debugging CUDA errors\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549cd3a0",
   "metadata": {
    "id": "549cd3a0"
   },
   "outputs": [],
   "source": [
    "!echo $CUDA_VISIBLE_DEVICES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f879c40b",
   "metadata": {
    "id": "f879c40b"
   },
   "outputs": [],
   "source": [
    "# Single GPU\n",
    "\n",
    "import faiss\n",
    "\n",
    "embedding_size = 384\n",
    "n_clusters = 16\n",
    "top_k_hits = 10\n",
    "\n",
    "quantizer = faiss.IndexFlatL2(embedding_size)\n",
    "index = faiss.IndexIVFFlat(quantizer, embedding_size, n_clusters, faiss.METRIC_L2)\n",
    "\n",
    "# Number of clusters to explorer at search time.\n",
    "# We will search for nearest neighbors in 8 clusters\n",
    "index.nprobe = 8\n",
    "\n",
    "ngpus = faiss.get_num_gpus()\n",
    "print(\"Number of GPUs:\", ngpus)\n",
    "\n",
    "res = faiss.StandardGpuResources()  # use a single GPU\n",
    "gpu_index_flat = faiss.index_cpu_to_gpu(res, 0, index)\n",
    "print(\"Now the index in on GPU.\")\n",
    "\n",
    "# Train the index to find a suitable clustering\n",
    "assert not gpu_index_flat.is_trained\n",
    "gpu_index_flat.train(corpus_embeddings)\n",
    "assert gpu_index_flat.is_trained\n",
    "print(\"Training complete!\")\n",
    "\n",
    "gpu_index_flat.add(corpus_embeddings)  # add vectors to the index\n",
    "print(gpu_index_flat.ntotal, \"added.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af6b376",
   "metadata": {
    "id": "7af6b376"
   },
   "outputs": [],
   "source": [
    "# Multiple GPUs\n",
    "\n",
    "import faiss\n",
    "\n",
    "embedding_size = 384\n",
    "n_clusters = 64\n",
    "top_k_hits = 10\n",
    "\n",
    "\n",
    "quantizer = faiss.IndexFlatL2(embedding_size)\n",
    "index = faiss.IndexIVFFlat(quantizer, embedding_size, n_clusters)\n",
    "\n",
    "# Number of clusters to explorer at search time.\n",
    "# We will search for nearest neighbors in 8 clusters\n",
    "index.nprobe = 8\n",
    "\n",
    "\n",
    "print(\"Moving index to gpu before training\")\n",
    "\n",
    "ngpus = faiss.get_num_gpus()\n",
    "print(\"Number of GPUs:\", ngpus)\n",
    "\n",
    "gpu_index_flat = faiss.index_cpu_to_all_gpus(index)\n",
    "print(\"Now the index in on GPU.\")\n",
    "\n",
    "# Train the index to find a suitable clustering\n",
    "assert not gpu_index_flat.is_trained\n",
    "gpu_index_flat.train(corpus_embeddings)\n",
    "assert gpu_index_flat.is_trained\n",
    "print(\"Training complete!\")\n",
    "\n",
    "# Add vectors to the index\n",
    "gpu_index_flat.add(corpus_embeddings)\n",
    "print(gpu_index_flat.ntotal, \"added.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02fd8b9f9ee54c91b62db712026cc954": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5e3a92f8d04d45698410b413e224eedf",
      "placeholder": "​",
      "style": "IPY_MODEL_d3dd1c9402b0414483d027cbabe51be9",
      "value": " 258/258 [00:11&lt;00:00, 42.89it/s]"
     }
    },
    "2e4a33a0f7f74eaf9430a31ad6a12cda": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_495d9ee4f07d4ba99a02e18d3508c73f",
       "IPY_MODEL_e711bf223a594e3da579717bc2dc7192",
       "IPY_MODEL_02fd8b9f9ee54c91b62db712026cc954"
      ],
      "layout": "IPY_MODEL_f266a00bd38a4698a084377341688a9d"
     }
    },
    "3268379f635a4ee08a812115a71ea807": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "495d9ee4f07d4ba99a02e18d3508c73f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cc14214bb177429e94aea83147a41276",
      "placeholder": "​",
      "style": "IPY_MODEL_e1af658017b94ecdad420ac828614379",
      "value": "Batches: 100%"
     }
    },
    "5e3a92f8d04d45698410b413e224eedf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cc14214bb177429e94aea83147a41276": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d3dd1c9402b0414483d027cbabe51be9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e1af658017b94ecdad420ac828614379": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e711bf223a594e3da579717bc2dc7192": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3268379f635a4ee08a812115a71ea807",
      "max": 258,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fbc8b9ba4ac24cfba548d789966083c5",
      "value": 258
     }
    },
    "f266a00bd38a4698a084377341688a9d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fbc8b9ba4ac24cfba548d789966083c5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
